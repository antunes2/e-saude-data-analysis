import pandas as pd
import numpy as np
from pathlib import Path
from src.config.database import DatabaseConfig
import logging

class HealthETLPipeline:

    """
    Pipeline ETL para dados de sa√∫de de Curitiba.
    
    ETL = Extract, Transform, Load
    Esta classe orquestra todo o processo de dados.
    """

    def __init__(self):
        self.raw_data_path = Path('data/raw/saude')
        self.processed_data_path = Path('data/processed/')
        self.df = None # DataFrame principal onde trabalharemos
        self.stats = {}  # Para guardar estat√≠sticas do processo

    def run(self):
        """
        M√©todo principal que executa o pipeline completo.
        """
        print("üîÑ Iniciando pipeline de sa√∫de...")

        try:

            self.extract() #Extra√ß√£o

            self.transform() #Transforma√ß√£o

            self.load() #Carga

            self._print_statistics()
            print("‚úÖ Pipeline de sa√∫de conclu√≠do com sucesso!")

        except Exception as e:

            print(f"‚ùå Erro no pipeline de sa√∫de: {e}")
            raise

    def extract(self):
        """
        Extrai os dados brutos dos arquivos CSV.
        """
        print("üì• Extraindo dados brutos...")

        # 1. Encontrar todos os arquivos CSV na pasta raw_data_path
        csv_files = list(self.raw_data_path.glob('*.csv'))

        if not csv_files:
            raise FileNotFoundError(f"Nenhum arquivo CSV encontrado em {self.raw_data_path}")
        
        print(f"Encontrados {len(csv_files)} arquivos CSV.")

        # 2 Definir tipos para colunas de c√≥digos (podem conter zeros √† esquerda)
        dtype_spec = {
        'C√≥digo da Unidade': 'str',
        'C√≥digo do Procedimento': 'str', 
        'C√≥digo do CBO': 'str',
        'C√≥digo do CID': 'str',
        'CID do Internamento': 'str',
        'cod_usuario': 'str',           # Pode ter zeros √† esquerda
        'cod_profissional': 'str'       # Pode ter zeros √† esquerda
        }

        # 3. Ler e combinar todos os arquivos em um √∫nico DataFrame
        data_frames = []

        for csv_file in csv_files:
            print(f"Lendo arquivo: {csv_file.name}")

            # Ler CSV com configura√ß√µes para dados brasileiros
        df_temp = pd.read_csv(
            csv_file,
            sep=';',               # Separador comum em CSVs BR
            encoding='latin-1',    # Encoding comum em dados BR  
            low_memory=False,      # Evita warnings de mem√≥ria
            dtype=dtype_spec,      # c√≥digos como string
            parse_dates=False      # Parse datas manual
        )
        
        data_frames.append(df_temp)

        # 4. Concatenar todos os DataFrames
        self.df = pd.concat(data_frames, ignore_index=True)

        # 5. Salvar estat√≠sticas 
        self.stats['arquivos_processados'] = len(csv_files)
        self.stats['registros_extraidos'] = len(self.df)
        self.stats['colunas_extra√≠das'] = list(self.df.columns)

        # 6. Verifica√ß√£o de qualidade
        self._validate_data_quality()

    def  transform(self):
        """Fase 2: Limpeza e transforma√ß√£o dos dados"""
        print("üõ†Ô∏è  Fase 2 - Transformando dados...")
        
        # Ordem CR√çTICA das transforma√ß√µes
        self._convert_dates()           # 1. Datas primeiro
        self._convert_numeric()         # 2. Depois n√∫meros
        self._handle_missing_values()   # 3. Tratar nulos
        self._create_derived_columns()  # 4. Novas colunas
        self._create_natural_key()      # 5. Chave √∫nica
        
        print("   ‚úÖ Transforma√ß√£o conclu√≠da")
        self._validate_transformation()
        

    
    def load(self):
        """
        Carrega os dados transformados para o banco de dados.
        """
        print("üíæ Carregando dados no banco...")


    def _validate_data_quality(self):
        """Faz verifica√ß√µes b√°sicas de qualidade dos dados extra√≠dos"""
        print("   üîç Validando qualidade dos dados...")
        
        # Verificar se c√≥digos importantes n√£o foram convertidos para num√©ricos
        code_columns = ['C√≥digo da Unidade', 'C√≥digo do Procedimento','C√≥digo do CBO', 
                        'CID do Internamento', 'cod_usuario', 'cod_profissional', 'C√≥digo do CID']
        
        for col in code_columns:
            if col in self.df.columns:
                # Amostra dos primeiros valores
                sample = self.df[col].head(3).tolist()
                print(f"      {col}: {sample}")
                
                # Verificar se h√° zeros √† esquerda
                if self.df[col].dtype == 'object':  # string
                    has_leading_zeros = self.df[col].astype(str).str.startswith('0').any()
                    if has_leading_zeros:
                        print(f"      ‚úÖ {col} - Zeros √† esquerda preservados")
                    else:
                        print(f"      ‚ÑπÔ∏è  {col} - Sem zeros √† esquerda")


    def _print_statistics(self):
        """Exibe estat√≠sticas do processo"""
        print("\nüìä Estat√≠sticas do Processamento:")
        for key, value in self.stats.items():
            print(f"   {key}: {value}")