import pandas as pd
import numpy as np
from pathlib import Path
from src.config.database import DatabaseConfig
from scripts.loaders.dimension_loader import DimensionLoader
import logging
from datetime import date


class HealthETLPipeline:

    """
    Pipeline ETL para dados de sa√∫de de Curitiba.
    
    ETL = Extract, Transform, Load
    Esta classe orquestra todo o processo de dados.
    """

    def __init__(self):
        self.raw_data_path = Path('data/raw/saude')
        self.processed_data_path = Path('data/processed/')
        self.df = None # DataFrame principal onde trabalharemos
        self.stats = {}  # Para guardar estat√≠sticas do processo

    def run(self):
        """
        M√©todo principal que executa o pipeline completo.
        """
        print("üîÑ Iniciando pipeline de sa√∫de...")

        try:

            self.extract() #Extra√ß√£o

            self.transform() #Transforma√ß√£o

            self.load() #Carga

            self._print_statistics()
            print("‚úÖ Pipeline de sa√∫de conclu√≠do com sucesso!")

        except Exception as e:

            print(f"‚ùå Erro no pipeline de sa√∫de: {e}")
            raise

    def extract(self):
        """
        Extrai os dados brutos dos arquivos CSV.
        """
        print("üì• Extraindo dados brutos...")

        # 1. Encontrar todos os arquivos CSV na pasta raw_data_path
        csv_files = list(self.raw_data_path.glob('*.csv'))

        if not csv_files:
            raise FileNotFoundError(f"Nenhum arquivo CSV encontrado em {self.raw_data_path}")
        
        print(f"Encontrados {len(csv_files)} arquivos CSV.")

        # 2 Definir tipos para colunas de c√≥digos (podem conter zeros √† esquerda)
        dtype_spec = {
        'C√≥digo da Unidade': 'str',
        'C√≥digo do Procedimento': 'str', 
        'C√≥digo do CBO': 'str',
        'C√≥digo do CID': 'str',
        'CID do Internamento': 'str',
        'cod_usuario': 'str',           # Pode ter zeros √† esquerda
        'cod_profissional': 'str'       # Pode ter zeros √† esquerda
        }

        # 3. Ler e combinar todos os arquivos em um √∫nico DataFrame
        data_frames = []

        for csv_file in csv_files:
            print(f"Lendo arquivo: {csv_file.name}")

            # Ler CSV com configura√ß√µes para dados brasileiros
            df_temp = pd.read_csv(
                csv_file,
                sep=';',               # Separador comum em CSVs BR
                encoding='latin-1',    # Encoding comum em dados BR  
                low_memory=False,      # Evita warnings de mem√≥ria
                dtype=dtype_spec,      # c√≥digos como string
                parse_dates=False      # Parse datas manual
            )
            
            data_frames.append(df_temp)

        # 4. Concatenar todos os DataFrames e renomear Munic√≠pio
        self.df = pd.concat(data_frames, ignore_index=True)
        if 'Munic√≠cio' in self.df.columns:
            self.df.rename(columns={'Munic√≠cio': 'Munic√≠pio'}, inplace=True)
    
        # üöÄ MELHORIA FUTURA: Para projetos maiores, criar fun√ß√£o _standardize_column_names()
        # que gerencia m√∫ltiplas inconsist√™ncias de nomenclatura automaticamente

        # 5. Salvar estat√≠sticas 
        self.stats['arquivos_processados'] = len(csv_files)
        self.stats['registros_extraidos'] = len(self.df)
        self.stats['colunas_extra√≠das'] = list(self.df.columns)

        # 6. Verifica√ß√£o de qualidade
        self._validate_data_quality()

    def  transform(self):
        """Fase 2: Limpeza e transforma√ß√£o dos dados"""
        print("üõ†Ô∏è  Fase 2 - Transformando dados...")
        
        # Ordem CR√çTICA das transforma√ß√µes
        self._convert_dates()           # 1. Datas primeiro
        self._convert_numeric()         # 2. Depois n√∫meros
        self._handle_missing_values()   # 3. Tratar nulos
        self._create_derived_columns()  # 4. Novas colunas
        self._create_natural_key()      # 5. Chave √∫nica
        
        print("   ‚úÖ Transforma√ß√£o conclu√≠da")
        self._validate_transformation()
        
    def _convert_dates(self):
        """Converte colunas de data para datetime"""
        date_cols = ['Data do Atendimento', 'Data de Nascimento']
        
        for col in date_cols:
            if col in self.df.columns:
                self.df[col] = pd.to_datetime(
                    self.df[col], 
                    format='%d/%m/%Y %H:%M:%S',
                    errors='coerce'
                    )
        
        print("  üîÑ Datas convertidas para datetime")

    def _convert_numeric(self):
        """Trata valores missing e converte num√©ricos SIMPLES"""
    
        # Colunas que queremos como inteiros
        int_columns = [
            'Qtde Prescrita Farm√°cia Curitibana',
            'Qtde Dispensada Farm√°cia Curitibana', 
            'Qtde de Medicamento N√£o Padronizado',
            'C√¥modos'
        ]
        
        for col in int_columns:
            if col in self.df.columns:
                # Converte para num√©rico, trata erros, depois para inteiro
                self.df[col] = pd.to_numeric(self.df[col], errors='coerce')
                self.df[col] = self.df[col].fillna(0).astype(int)
                print(f"   ‚úÖ {col} convertida para inteiro")
    
    def _handle_missing_values(self):
        """Trata valores missing em colunas categ√≥ricas importantes"""
        
        print("  üîÑ Tratando valores missing...")

        total_nulos_inicial = self.df.isnull().sum().sum()

        # Apenas colunas que N√ÉO podem ser NULL na tabela fato
        CRITICAL_COLUMNS = {
            'Sexo': 'N√£o Informado',
            'Solicita√ß√£o de Exames': 'N√£o Informado',
            'Encaminhamento para Atendimento Especialista': 'N√£o Informado', 
            'Desencadeou Internamento': 'N√£o Informado'}
        
        for col, fill_value in CRITICAL_COLUMNS.items():
            if col in self.df_columns:
                n_nulos = self.df[col].isna().sum()
                if n_nulos > 0:
                    self.df[col] = self.df[col].fillna(fill_value)
                    print(f"      ‚úÖ {col}: {n_nulos} nulos ‚Üí '{fill_value}'")
                else:
                    print(f"      ‚ÑπÔ∏è  {col}: sem nulos")

        # Valida√ßao da integridade de dados
        total_nulos_final = self.df.isna().sum().sum()

        print(f"   üîç Total de valores missing antes: {total_nulos_inicial}, depois: {total_nulos_final}")

        # Valida√ßao final
        self._validate_data_integrity()

    def _create_derived_columns(self):
        """Cria novas colunas derivadas (feature engineering)"""
        print("  üîÑ Criando colunas derivadas...")
        
        # Idade do paciente
        self.df['idade'] = (self.df['Data do Atendimento'] - self.df['Data de Nascimento']).dt.days // 365
        
        # Diferen√ßa entre prescrito e dispensado
        self.df['diff_prescrito_dispensado'] = self.df['Qtde Prescrita Farm√°cia Curitibana'] - self.df['Qtde Dispensada Farm√°cia Curitibana']
        
        # Flag para atendimento que gerou interna√ß√£o
        self.df['gerou_internamento'] = self.df['Desencadeou Internamento'].apply(lambda x: 1 if x == 'Sim' else 0)
        
        # Flag para morador de Curitiba ou regi√£o metropolitana
        self.df['morador_curitiba_rm'] = self.df['Munic√≠pio'].apply(lambda x: "Curitiba" if x == "Curitiba" else "Regi√£o Metropolitana")

        # Per√≠dodo do dia do atendimento
        self.df['periodo_dia'] = self.df['Data do Atendimento'].dt.hour.apply(
        lambda x: 'Manh√£' if 6 <= x < 12 else 
                  'Tarde' if 12 <= x < 18 else 
                  'Noite' if 18 <= x < 24 else 'Madrugada')
        
        # Faixa et√°ria
        self.df['faixa_etaria'] = self.df['idade'].apply(
        lambda x: 'Crian√ßa' if x <= 12 else 
                  'Adolescente' if x <= 19 else 
                  'Adulto' if x <= 59 else 'Idoso'
    )

        print("   ‚úÖ Colunas derivadas criadas")

    def _create_natural_key(self):
        """Cria a chave natural √∫nica para cada atendimento."""
        print("  üîÑ Criando chave natural √∫nica...")
        
        self.df['chave_natural'] = (
            self.df['Data do Atendimento'].astype(str) + 
            '_' + self.df['C√≥digo da Unidade'].astype(str) + 
            '_' + self.df['cod_usuario'].astype(str) + 
            '_' + self.df['C√≥digo do Procedimento'].astype(str)
        )
        
        # Valida se realmente √© √∫nica
        total_registros = len(self.df)
        registros_unicos = self.df['chave_natural'].nunique()

        print(f"      üìä Registros: {total_registros:,}")
        print(f"      üîë Chaves √∫nicas: {registros_unicos:,}")

        if total_registros != registros_unicos:
            raise ValueError(f"Chave natural n√£o √© √∫nica! Total registros: {total_registros}, √∫nicos: {registros_unicos}")
        else:
            print("      ‚úÖ Chave natural √© √∫nica!")


    def load(self):
        """
        Carrega os dados transformados para o banco de dados.
        """
        print("üíæ Carregando dados no banco...")

        try:
            with DatabaseConfig.get_connection() as conn:
                # 1. Carregar dimensoes primeiro
                dimension_loader = DimensionLoader()
                dimension_maps = dimension_loader.load_all(self.df, conn)

                # 2. Guardar os mapeamentos para usar na tabela fato
                self.dimension_maps = dimension_maps

                # 3. Estat√≠sticas
                self.starts['dimensoes_carregadas'] = len(dimension_maps)
                for dim_name, mapping in dimension_maps.items():
                    self.stats[f'registros_{dim_name}_inseridos'] = len(mapping)

                print("   ‚úÖ Dimens√µes carregadas com sucesso")

        except Exception as e:
            print(f"‚ùå Erro ao carregar dados: {e}")
            raise


    def _validate_data_quality(self):
        """Faz verifica√ß√µes b√°sicas de qualidade dos dados extra√≠dos"""
        print("   üîç Validando qualidade dos dados...")
        
        # Verificar se c√≥digos importantes n√£o foram convertidos para num√©ricos
        code_columns = ['C√≥digo da Unidade', 'C√≥digo do Procedimento','C√≥digo do CBO', 
                        'CID do Internamento', 'cod_usuario', 'cod_profissional', 'C√≥digo do CID']
        
        for col in code_columns:
            if col in self.df.columns:
                # Amostra dos primeiros valores
                sample = self.df[col].head(3).tolist()
                print(f"      {col}: {sample}")
                
                # Verificar se h√° zeros √† esquerda
                if self.df[col].dtype == 'object':  # string
                    has_leading_zeros = self.df[col].astype(str).str.startswith('0').any()
                    if has_leading_zeros:
                        print(f"      ‚úÖ {col} - Zeros √† esquerda preservados")
                    else:
                        print(f"      ‚ÑπÔ∏è  {col} - Sem zeros √† esquerda")

    def _validate_data_integrity(self):
        """Valida que colunas essenciais est√£o preenchidas"""
        print("   üîç Validando integridade dos dados...")
        
        ESSENTIAL_COLUMNS = [
            'Data do Atendimento',
            'Data de Nascimento',
            'Sexo', 
            'C√≥digo da Unidade',
            'C√≥digo do Procedimento',
            'C√≥digo do CID',
            'C√≥digo do CBO',
            'cod_usuario'
        ]
        
        issues = []
        for col in ESSENTIAL_COLUMNS:
            if col in self.df.columns:
                n_nulos = self.df[col].isna().sum()
                if n_nulos > 0:
                    issues.append(f"{col}: {n_nulos} nulos")
                else:
                    print(f"      ‚úÖ {col}: Completo")
        
        if issues:
            print(f"      ‚ö†Ô∏è  Problemas encontrados: {', '.join(issues)}")
        else:
            print("      ‚úÖ Todas colunas essenciais est√£o completas!") 

    def _print_statistics(self):
        """Exibe estat√≠sticas do processo"""
        print("\nüìä Estat√≠sticas do Processamento:")
        for key, value in self.stats.items():
            print(f"   {key}: {value}")