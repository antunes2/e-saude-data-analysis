import pandas as pd
import numpy as np
from pathlib import Path
from src.config.database import DatabaseConfig
from scripts.loaders.dimension_loader import DimensionLoader
import logging
from datetime import date


class HealthETLPipeline:

    """
    Pipeline ETL para dados de saÃºde de Curitiba.
    
    ETL = Extract, Transform, Load
    Esta classe orquestra todo o processo de dados.
    """

    def __init__(self):
        self.raw_data_path = Path('data/raw/saude')
        self.processed_data_path = Path('data/processed/')
        self.df = None # DataFrame principal onde trabalharemos
        self.stats = {}  # Para guardar estatÃ­sticas do processo

    def run(self):
        """
        MÃ©todo principal que executa o pipeline completo.
        """
        print("ğŸ”„ Iniciando pipeline de saÃºde...")

        try:

            self.extract() #ExtraÃ§Ã£o

            self.transform() #TransformaÃ§Ã£o

            self.load() #Carga

            self._print_statistics()
            print("âœ… Pipeline de saÃºde concluÃ­do com sucesso!")

        except Exception as e:

            print(f"âŒ Erro no pipeline de saÃºde: {e}")
            raise

    def extract(self):
        """
        Extrai os dados brutos dos arquivos CSV.
        """
        print("ğŸ“¥ Extraindo dados brutos...")

        # 1. Encontrar todos os arquivos CSV na pasta raw_data_path
        csv_files = list(self.raw_data_path.glob('*.csv'))

        if not csv_files:
            raise FileNotFoundError(f"Nenhum arquivo CSV encontrado em {self.raw_data_path}")
        
        print(f"Encontrados {len(csv_files)} arquivos CSV.")

        # 2 Definir tipos para colunas de cÃ³digos (podem conter zeros Ã  esquerda)
        dtype_spec = {
        'CÃ³digo da Unidade': 'str',
        'CÃ³digo do Procedimento': 'str', 
        'CÃ³digo do CBO': 'str',
        'CÃ³digo do CID': 'str',
        'CID do Internamento': 'str',
        'cod_usuario': 'str',           # Pode ter zeros Ã  esquerda
        'cod_profissional': 'str'       # Pode ter zeros Ã  esquerda
        }

        # 3. Ler e combinar todos os arquivos em um Ãºnico DataFrame
        data_frames = []

        for csv_file in csv_files:
            print(f"Lendo arquivo: {csv_file.name}")

            # Ler CSV com configuraÃ§Ãµes para dados brasileiros
            df_temp = pd.read_csv(
                csv_file,
                sep=';',               # Separador comum em CSVs BR
                encoding='latin-1',    # Encoding comum em dados BR  
                low_memory=False,      # Evita warnings de memÃ³ria
                dtype=dtype_spec,      # cÃ³digos como string
                parse_dates=False      # Parse datas manual
            )
            
            data_frames.append(df_temp)

        # 4. Concatenar todos os DataFrames e renomear MunicÃ­pio
        self.df = pd.concat(data_frames, ignore_index=True)
        if 'MunicÃ­cio' in self.df.columns:
            self.df.rename(columns={'MunicÃ­cio': 'MunicÃ­pio'}, inplace=True)
    
        # ğŸš€ MELHORIA FUTURA: Para projetos maiores, criar funÃ§Ã£o _standardize_column_names()
        # que gerencia mÃºltiplas inconsistÃªncias de nomenclatura automaticamente

        # 5. Salvar estatÃ­sticas 
        self.stats['arquivos_processados'] = len(csv_files)
        self.stats['registros_extraidos'] = len(self.df)
        self.stats['colunas_extraÃ­das'] = list(self.df.columns)

        # 6. VerificaÃ§Ã£o de qualidade
        self._validate_data_quality()

    def  transform(self):
        """Fase 2: Limpeza e transformaÃ§Ã£o dos dados"""
        print("ğŸ› ï¸  Fase 2 - Transformando dados...")
        
        # Ordem CRÃTICA das transformaÃ§Ãµes
        self._convert_dates()           # 1. Datas primeiro
        self._convert_numeric()         # 2. Depois nÃºmeros
        self._handle_missing_values()   # 3. Tratar nulos
        self._create_derived_columns()  # 4. Novas colunas
        self._create_natural_key()      # 5. Chave Ãºnica
        
        print("   âœ… TransformaÃ§Ã£o concluÃ­da")
        self._validate_transformation()
        
    def _convert_dates(self):
        """Converte colunas de data para datetime"""
        date_cols = ['Data do Atendimento', 'Data de Nascimento']
        
        for col in date_cols:
            if col in self.df.columns:
                self.df[col] = pd.to_datetime(
                    self.df[col], 
                    format='%d/%m/%Y %H:%M:%S',
                    errors='coerce'
                    )
        
        print("  ğŸ”„ Datas convertidas para datetime")

    def _convert_numeric(self):
        """Trata valores missing e converte numÃ©ricos SIMPLES"""
    
        # Colunas que queremos como inteiros
        int_columns = [
            'Qtde Prescrita FarmÃ¡cia Curitibana',
            'Qtde Dispensada FarmÃ¡cia Curitibana', 
            'Qtde de Medicamento NÃ£o Padronizado',
            'CÃ´modos'
        ]
        
        for col in int_columns:
            if col in self.df.columns:
                # Converte para numÃ©rico, trata erros, depois para inteiro
                self.df[col] = pd.to_numeric(self.df[col], errors='coerce')
                self.df[col] = self.df[col].fillna(0).astype(int)
                print(f"   âœ… {col} convertida para inteiro")
    
    def _handle_missing_values(self):
        """Trata valores missing em colunas categÃ³ricas importantes"""
        
        print("  ğŸ”„ Tratando valores missing...")

        total_nulos_inicial = self.df.isnull().sum().sum()

        # Apenas colunas que NÃƒO podem ser NULL na tabela fato
        CRITICAL_COLUMNS = {
            'Sexo': 'NÃ£o Informado',
            'SolicitaÃ§Ã£o de Exames': 'NÃ£o Informado',
            'Encaminhamento para Atendimento Especialista': 'NÃ£o Informado', 
            'Desencadeou Internamento': 'NÃ£o Informado'}
        
        for col, fill_value in CRITICAL_COLUMNS.items():
            if col in self.df_columns:
                n_nulos = self.df[col].isna().sum()
                if n_nulos > 0:
                    self.df[col] = self.df[col].fillna(fill_value)
                    print(f"      âœ… {col}: {n_nulos} nulos â†’ '{fill_value}'")
                else:
                    print(f"      â„¹ï¸  {col}: sem nulos")

        # ValidaÃ§ao da integridade de dados
        total_nulos_final = self.df.isna().sum().sum()

        print(f"   ğŸ” Total de valores missing antes: {total_nulos_inicial}, depois: {total_nulos_final}")

        # ValidaÃ§ao final
        self._validate_data_integrity()

    def _create_derived_columns(self):
        """Cria novas colunas derivadas (feature engineering)"""
        print("  ğŸ”„ Criando colunas derivadas...")
        
        # Idade do paciente
        self.df['idade'] = (self.df['Data do Atendimento'] - self.df['Data de Nascimento']).dt.days // 365
        
        # DiferenÃ§a entre prescrito e dispensado
        self.df['diff_prescrito_dispensado'] = self.df['Qtde Prescrita FarmÃ¡cia Curitibana'] - self.df['Qtde Dispensada FarmÃ¡cia Curitibana']
        
        # Flag para atendimento que gerou internaÃ§Ã£o
        self.df['gerou_internamento'] = self.df['Desencadeou Internamento'].apply(lambda x: 1 if x == 'Sim' else 0)
        
        # Flag para morador de Curitiba ou regiÃ£o metropolitana
        self.df['morador_curitiba_rm'] = self.df['MunicÃ­pio'].apply(lambda x: "Curitiba" if x == "Curitiba" else "RegiÃ£o Metropolitana")

        # PerÃ­dodo do dia do atendimento
        self.df['periodo_dia'] = self.df['Data do Atendimento'].dt.hour.apply(
        lambda x: 'ManhÃ£' if 6 <= x < 12 else 
                  'Tarde' if 12 <= x < 18 else 
                  'Noite' if 18 <= x < 24 else 'Madrugada')
        
        # Faixa etÃ¡ria
        self.df['faixa_etaria'] = self.df['idade'].apply(
        lambda x: 'CrianÃ§a' if x <= 12 else 
                  'Adolescente' if x <= 19 else 
                  'Adulto' if x <= 59 else 'Idoso'
    )

        print("   âœ… Colunas derivadas criadas")

    def _create_natural_key(self):
        """Cria a chave natural Ãºnica para cada atendimento."""
        print("  ğŸ”„ Criando chave natural Ãºnica...")
        
        self.df['chave_natural'] = (
            self.df['Data do Atendimento'].astype(str) + 
            '_' + self.df['CÃ³digo da Unidade'].astype(str) + 
            '_' + self.df['cod_usuario'].astype(str) + 
            '_' + self.df['CÃ³digo do Procedimento'].astype(str)
        )
        
        # Valida se realmente Ã© Ãºnica
        total_registros = len(self.df)
        registros_unicos = self.df['chave_natural'].nunique()

        print(f"      ğŸ“Š Registros: {total_registros:,}")
        print(f"      ğŸ”‘ Chaves Ãºnicas: {registros_unicos:,}")

        if total_registros != registros_unicos:
            raise ValueError(f"Chave natural nÃ£o Ã© Ãºnica! Total registros: {total_registros}, Ãºnicos: {registros_unicos}")
        else:
            print("      âœ… Chave natural Ã© Ãºnica!")


    def load(self):
        """
        Carrega os dados transformados para o banco de dados.
        """
        print("ğŸ’¾ Carregando dados no banco...")

        try:
            with DatabaseConfig.get_connection() as conn:
                # 1. Carregar dimensoes primeiro
                dimension_loader = DimensionLoader()
                dimension_maps = dimension_loader.load_all(self.df, conn)

                # 2. Guardar os mapeamentos para usar na tabela fato
                self.dimension_maps = dimension_maps

                # 3. EstatÃ­sticas
                self.starts['dimensoes_carregadas'] = len(dimension_maps)
                for dim_name, mapping in dimension_maps.items():
                    self.stats[f'registros_{dim_name}_inseridos'] = len(mapping)

                print("   âœ… DimensÃµes carregadas com sucesso")

        except Exception as e:
            print(f"âŒ Erro ao carregar dados: {e}")
            raise


    def _validate_data_quality(self):
        """Faz verificaÃ§Ãµes bÃ¡sicas de qualidade dos dados extraÃ­dos"""
        print("   ğŸ” Validando qualidade dos dados...")
        
        # Verificar se cÃ³digos importantes nÃ£o foram convertidos para numÃ©ricos
        code_columns = ['CÃ³digo da Unidade', 'CÃ³digo do Procedimento','CÃ³digo do CBO', 
                        'CID do Internamento', 'cod_usuario', 'cod_profissional', 'CÃ³digo do CID']
        
        for col in code_columns:
            if col in self.df.columns:
                # Amostra dos primeiros valores
                sample = self.df[col].head(3).tolist()
                print(f"      {col}: {sample}")
                
                # Verificar se hÃ¡ zeros Ã  esquerda
                if self.df[col].dtype == 'object':  # string
                    has_leading_zeros = self.df[col].astype(str).str.startswith('0').any()
                    if has_leading_zeros:
                        print(f"      âœ… {col} - Zeros Ã  esquerda preservados")
                    else:
                        print(f"      â„¹ï¸  {col} - Sem zeros Ã  esquerda")

    def _validate_data_integrity(self):
        """Valida que colunas essenciais estÃ£o preenchidas"""
        print("   ğŸ” Validando integridade dos dados...")
        
        ESSENTIAL_COLUMNS = [
            'Data do Atendimento',
            'Data de Nascimento',
            'Sexo', 
            'CÃ³digo da Unidade',
            'CÃ³digo do Procedimento',
            'CÃ³digo do CID',
            'CÃ³digo do CBO',
            'cod_usuario'
        ]
        
        issues = []
        for col in ESSENTIAL_COLUMNS:
            if col in self.df.columns:
                n_nulos = self.df[col].isna().sum()
                if n_nulos > 0:
                    issues.append(f"{col}: {n_nulos} nulos")
                else:
                    print(f"      âœ… {col}: Completo")
        
        if issues:
            print(f"      âš ï¸  Problemas encontrados: {', '.join(issues)}")
        else:
            print("      âœ… Todas colunas essenciais estÃ£o completas!") 

    def _print_statistics(self):
        """Exibe estatÃ­sticas do processo"""
        print("\nğŸ“Š EstatÃ­sticas do Processamento:")
        for key, value in self.stats.items():
            print(f"   {key}: {value}")